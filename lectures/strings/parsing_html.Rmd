---
title: "rvest and regex"
author: 
date: 
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true # toc_float option to float the table of contents to the left of the main document content. floating table of contents will always be visible even when the document is scrolled
      #collapsed: false # collapsed (defaults to TRUE) controls whether the TOC appears with only the top-level (e.g., H2) headers. If collapsed initially, the TOC is automatically expanded inline when necessary
      #smooth_scroll: true # smooth_scroll (defaults to TRUE) controls whether page scrolls are animated when TOC items are navigated to via mouse clicks
    number_sections: true
    fig_caption: true # ? this option doesn't seem to be working for figure inserted below outside of r code chunk    
    highlight: tango # Supported styles include "default", "tango", "pygments", "kate", "monochrome", "espresso", "zenburn", and "haddock" (specify null to prevent syntax    
    theme: default # theme specifies the Bootstrap theme to use for the page. Valid themes include default, cerulean, journal, flatly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, and yeti.
    df_print: tibble #options: default, tibble, paged
    keep_md: true # may be helpful for storing on github
    
---

# `rvest` package

> Wrappers around the `xml2` and `httr` packages to make it easy to download, then manipulate, HTML and XML.

*Source: `rvest` package documentation*

```{r, message=FALSE}
library(tidyverse)
library(rvest)
```

Why use the `rvest` package?

- `rvest` makes it easy to parse HTML
- First, we use the `read_html()` function to [read in the HTML](#reading-html) and convert it to an `xml_document`/`xml_node` object
- A **node** is just an HTML **element**
- HTML is made up of nested elements, so once we've read in the HTML to a `xml_node` object, we can easily traverse the nested nodes (ie. children elements) and [parse the HTML](#parsing-html)
- `rvest` comes with many helpful functions to search and extract various parts of the HTML
  - `html_node()`/`html_nodes()`: Search and extract node(s) (ie. HTML elements)
  - `html_text()`: Extract the content between HTML tags
  - `html_attr()`/`html_attrs()`: Extract the attribute(s) of HTML tags


## Reading HTML

__The `read_html()` function__:

```{r, eval = FALSE}
?read_html

# SYNTAX AND DEFAULT VALUES
read_html(x, encoding = "", ..., options = c("RECOVER", "NOERROR", "NOBLANKS"))
```

- Arguments:
  - `x`: The input can be a string containing HTML or url to the webpage you want to scrape
- Output:
  - The HTML that is read in will be returned as an `rvest` `xml_document`/`xml_node` object and can be easily parsed
  - You can also view the raw HTML using `as.character()`

<br>
<details><summary>**Example**: Using `read_html()` to read in HTML from string</summary>

```{r}
html <- read_html("<h1>This is a heading.</h1><p>This is a paragraph.</p>")

# View object
html

# View class of object
class(html)

# View raw HTML
as.character(html)
```

</details>

<br>
<details><summary>**Example**: Using `read_html()` to scrape the page `https://corona.help/`</summary>

CRYSTAL - BEFORE WE APPLY READ_HTML TO THE PAGE, CAN WE SHOW STUDENTS HOW TO EXAMINE THE HTML USING THEIR BROWSER?

- FIRST LET'S LOOK AT THE WEBPAGE
- SECOND, LET'S HAVE THEM "INSPECT PAGE" AND "VIEW PAGE SOURCE"
  - WHAT DO THESE TWO THINGS MEAN? WHAT IS DIFFERENCE BETWEEN INSPECT PAGE AND VIEW PAGE SOURCE?
    - https://medium.com/@codebyamir/view-source-vs-inspect-element-ca52f06110a0
    - DO YOU RECOMMEND ONE VS. THE OTHER?
  - HOW DO YOU DO THESE TWO THINGS? IN PC, YOU RIGHT-CLICK. WHAT ABOUT MAC?
  - 

```{r}
corona <- read_html("https://corona.help/")

# View object
str(corona)
corona
```

```{r, eval=FALSE}
# View raw HTML
as.character(corona)

str(as.character(corona))
typeof(as.character(corona))
```

</details>

## Parsing HTML

__The `html_node()` and `html_nodes()` functions__:

```{r, eval = FALSE}
?html_node

# SYNTAX
html_node(x, css, xpath)


?html_nodes

# SYNTAX
html_nodes(x, css, xpath)
```

- Arguments:
  - `x`: An `rvest` `xml_document`/`xml_node` object (use `read_html()` to get this)
  - `css`: Selector (can select by HTML tag name, its attributes, etc.)
    - CRYSTAL - CAN WE PROVIDE AN INTUITIVE DESCRIPTION OF WHAT A CSS SELECTOR IS?
    - POSSIBLE TO SELECT RIGHT HTML TAG NAME/ATTRIBUTES ETC WITHOUT USING SELECTORGADGET OR SOMETHING LIKE THAT?
- Output:
  - `html_node()` returns the first element that it finds as an `rvest` `xml_node` object
    - CRYSTAL - RE-STATE WHAT AN XML_NODE OBJECT IS
  - `html_nodes()` returns all elements that it finds as an `rvest` `xml_nodeset` object
    - CRYSTAL - RE-STATE WHAT AN XML_NODESET OBJECT IS
  - Again, you can view the raw HTML using `as.character()`
    - CRYSTAL - ADD EXAMPLE SYNTAX

<br>
<details><summary>**Example**: Using `html_node()` and `html_nodes()` I</summary>

Remember that the input to `html_node()`/`html_nodes()` should be an `rvest` `xml_document`/`xml_node` object, which we can obtain from `read_html()`:

CRYSTAL - `html_node()` and `html_nodes()` assume we know which elements are in the xml_node/nodeset object. how do we find out which elements are in the node/nodeset object?
```{r}
html <- read_html("<p>Paragraph #1</p><p>Paragraph #2</p><p>Paragraph #3</p>")

# View class of object
class(html)
html
```

<br>
If we search for the `p` element using `html_node()`, it will return the first result:

```{r}
first_p <- html_node(html, 'p')

# View class of object
class(first_p)

# View raw HTML
as.character(first_p)
```

<br>
If we search for the `p` element using `html_nodes()`, it will return all results:

```{r}
all_p <- html_nodes(html, 'p')

# View class of object
class(all_p)

# View raw HTML
as.character(all_p)
```

<br>
Note that we could also use `%>%`:

```{r}
# These are equivalent to the above
first_p <- html %>% html_node('p')
all_p <- html %>% html_nodes('p')
```

</details>


<br>
<details><summary>**Example**: Using `html_node()` and `html_nodes()` II</summary>

Let's revisit the HTML we scraped from `https://corona.help/` in the previous example:

- imagine that our goal is to create a dataframe containing the table "Totals by country" [CRYSTAL - IS THIS WHAT WE ARE TRYING TO TELL THE STUDENTS?]
- IS THERE A WAY THAT WE CAN VIEW THE HTML CODE ASSOCIATED W/ THE TABLE ON THE https://corona.help/ website?
- GIVE SOME BASIC INTUITION/OVERVIEW OF GENERAL PROCESS OF SCRAPING AN HTML TABLE

```{r}
# Scraped HTML is stored in this `xml_document`/`xml_node` object
class(corona)
```

<br>
Select for the `table` element on that page using `html_node()`:

```{r}
# Since this table is the only table on the page, we can just use `html_node()`
corona_table <- corona %>% html_node('table')
corona_table
class(corona_table)
```

<br>
Can use `as.character(corona_table)` to print raw html code of `corona_table` [output omitted]
```{r}
as.character(corona_table)
```
CRYSTAL - HOW COME THIS DOESN'T WORK TO PRINT THE BODY OF THE HTML TABLE?
```{r, eval = FALSE}
corona_table
as.character(corona_table[2])
```


<br>
Select for all rows in the table (ie. `tr` element) using `html_nodes()`:

- CRYSTAL - IS IT ALWAYS THE CASE THAT WE SELECT/SCRAPE HTML TABLES BY ROWS RATHER THAN BY COLUMNS? IF SO, LET'S SAY THAT AND SAY WHY IF THERE IS A SUPER BRIEF EXPLANATION

```{r}
# We can chain `html_node()`/`html_nodes()` functions
corona_rows <- corona %>% html_node('table') %>% html_nodes('tr')

# Alternatively, we can use `table tr` as the selector to select all `tr` elements within a `table`
corona_rows <- corona %>% html_nodes('table tr')

# investigate object
head(corona_rows) # View first few rows
typeof(corona_rows)
class(corona_rows)
length(corona_rows) # number of elements
```

</details>

### Practicing regex

Below are some examples using the Coronavirus data from https://corona.help/. Recall that we have selected for all rows in the data table on that page:

CRYSTAL - CAN YOU GIVE AN OVERALL SUMMARY OF WHAT WE ARE TRYING TO DO W/ THE TABLE (E.G., CREATE DATAFRAME OF DATA FROM TABLE). WE CAN SAY WE ARE NOT DOING IT MOST EFFICIENT WAY CUZ POSSIBLE CUZ THE GOAL IS TO PRACTICE REGEX.

```{r}
# View first few rows
head(corona_rows)
corona_rows[1:5] # first five rows
corona_rows[c(1)] # header row
corona_rows[1] # header row
```

Let's convert this to raw HTML using `as.character()` to practice writing regular expressions:

```{r}
# Convert rows to raw HTML
rows <- as.character(corona_rows)[-c(1)] # [-c(1)] means skip header row

# investgate object named rows, which is a character vector
typeof(rows)
class(rows)
length(rows)

## View first few rows as raw HTML
  # note that printing via writeLines() is much prettier than printing via print()
  writeLines(head(rows, 2)) 
  
  #printing via print()
  #head(rows, 2)
```

<br>
<details><summary>**Example**: Using `str_subset()` to subset rows</summary>

FOR ALL OF THESE EXAMPLES BELOW [WHICH ARE EXCELLENT!]: IN THE CODE, PROVIDE A LINE OR TWO THAT USES FUNCTIONS LIKE STR_DETECT TO INVESTIGATE/IDENTIFY MATCHES BEFORE USING FUNCTIONS LIKE SUBSET, EXTRACT, ETC. TO CREATE THE OBJECT. 

Subset rows by country name:

- reminder: `str_subset` keeps elements of character vector for which `str_detect` is `TRUE` (i.e., keeps elements where the pattern "matches")

```{r}
subset_by_country <- str_subset(string = rows, pattern = 'United \\w+')
writeLines(subset_by_country)
```

</details>

<br>
<details><summary>**Example**: Using `str_extract()` to extract link for each row</summary>

CRYSTAL - SHOW HOW STUDENTS WOULD INVESTIGATE/KNOW THAT ALL LINKS FOLLOW THE SAME PATTERN

Since all links follow the same pattern, we can use regex to extract this info:

```{r}
links <- str_extract(string = rows, pattern = 'https://corona.help/country/[-a-z]+')

# View first few links
head(links)
```

</details>

<br>
<details><summary>**Example**: Using `str_match()` to extract country for each row</summary>

SHOW HOW STUDENTS CAN INVESTIGATE TO KNOW PATTERNS NECESSARY TO EXRACT COUNTRY

Since all countries are in a `div` element with the same attributes, we can use the following regex to extract the country name:

```{r}
countries <- str_match(string = rows, pattern = '<div style="height:100%;width:100%">([\\w ]+)</div>')

# View first few countries
head(countries)
```

</details>

<br>
<details><summary>**Example**: Using `str_match_all()` to extract number deaths and critical for each row</summary>

SHOW HOW STUDENTS CAN INVESTIGATE TO KNOW PATTERNS

Since both the number of deaths and critical are in a `td` element with the same `class` attribute, we can use the following regex to extract both numbers:

```{r}
num_danger <- str_match_all(string = rows, pattern = '<td class="text-danger">([\\d,]+)</td>')

# View matches for first few rows
head(num_danger)
```

</details>

<br>
<details><summary>**Example**: Using `str_replace_all()` to convert numeric values to thousands for each row</summary>

Rewrite all numeric values greater than one thousand in terms of `k`:

```{r}
num_to_k <- str_replace_all(string = rows, pattern = '>([\\d,]+),\\d{3}<', replacement = '>\\1k<')

# View replacements for first few rows
writeLines(head(num_to_k))
```

</details>
